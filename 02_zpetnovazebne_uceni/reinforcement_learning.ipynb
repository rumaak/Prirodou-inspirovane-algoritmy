{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zpětnovazební učení"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V tomto cvičení budeme pracovat s Open AI gym, což je open source rozhraní určené pro úkoly zpětnovazebního učení. Jeho hlavní výhodou je, že implementace různých typů algoritmů pro zpětnovazební učení je v něm celkem jednoduchá. Popis základních funkcí Open AI gym se nachází v kódu níž.\n",
    "\n",
    "Dnešní úkol bude naimplementovat agenta, který se učí chovat v nějakém prostředí (konkrétně v MountainCar) pomocí Q-učení.\n",
    "\n",
    "Q-učení je způsob, kdy se agent učí svou strategii, jak se chovat v daném prostředí, pomocí zpětné vazby, kterou od prostředí za své chování dostává. Na rozdíl od hladového agenta, který jen v každém stavu vybírá nový stav na základě akce, co maximalizuje jeho užitek, bere v potaz to, že mezi stavy existují vztahy, které jsou dány Bellmanovými rovnicemi.\n",
    "\n",
    "Nyní se tedy podíváme na příklad autíčka,které se snaží dostat do cíle, ale zatím se pohybuje náhodně."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ukážeme si, jak si vytvořit jednoduché prostředí *MountainCar*: https://gym.openai.com/envs/MountainCar-v0. \n",
    "\n",
    "Cílem je, aby se autíčko dostalo z údolí až nahoru k vlaječce, ale nemá dost silný motorek, takže se musí nejprve rozhoupat, aby tam vyjelo. V této základní verzi je zde v každém stavu náhodně zvolena akce pro pohyb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.reset()\n",
    "for i in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jen tak pro zajímavost existuje i například prostředí *CartPole*, kde je zase cílem vyvažovat tyčku, aby nespadla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\katie\\onedrive\\dokumenty\\documents\\skola\\matfyz\\phd\\prirodou-inspirovane-algoritmy\\02_zpetnovazebne_uceni\\gym\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vrátíme se zpět k *MountainCar*. Použijeme kódu výše a vytvoříme si do něj třídu pro agenta, který se v prostředí zatím bude chovat náhodně, což nám sice v tuto chvíli nepřinese nic užitečného, ale můžete ho později použít jako základ pro zpětnovazebního agenta. \n",
    "\n",
    "Stav agenta dvojice je pozice a rychlost, akce může být pohyb vlevo, vpravo a nebo se nepohnout. Agent bude mít dvě metody, jednu na to, aby věděl, jak se má chovat a druhou aby se uměl resetovat. Agenta totiž budeme trénovat v několika iteracích. Pro zajímavost si také vypíšeme, jak vypadá prostředí, ve kterém se agent pohybuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space: Box(-1.2000000476837158, 0.6000000238418579, (2,), float32)\n",
      "observation space low: [-1.2  -0.07]\n",
      "observation space high: [0.6  0.07]\n",
      "action space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "# Obecna trida pro agenta\n",
    "class RandomAgent:\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.train = True\n",
    "    \n",
    "    def act(self, observe, reward, done):\n",
    "        return self.actions.sample()\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "# Prostoru pozorovani a akci\n",
    "print('observation space:', env.observation_space)\n",
    "print('observation space low:', env.observation_space.low)\n",
    "print('observation space high:', env.observation_space.high)\n",
    "print('action space:', env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní si zkusíme napsat trénovací cyklus. Každá iterace for cyklu je jedna hra s novým náhodným začátkem (kolem minima). Ve while cyklu se trénují přechody mezi stavy agenta. Zároveň si pamatujeme celkovou odměnu a číslo kroku (jeden krok je provedení jedné akce), které se nám bude hodit pro logování trénovacích cyklu. K tomu, aby se agent mohl něco učit musí získávat od prostředí nějakou odměnu. V tomto příkladu by měl agent dostávat v každém kroku odměnu -1, když není v cílovém stavu a 0 pokud v něm je. Snižující se suma odměn totiž agenta nutí, aby prohledával prostředí, a tedy vyjel nahoru co nejdříve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = RandomAgent(env.action_space)\n",
    "total_rewards = []\n",
    "for i in range(1000):\n",
    "    obs = env.reset()\n",
    "    agent.reset()    \n",
    "    done = False\n",
    "    \n",
    "    r = 0\n",
    "    R = 0 # celkova odmena - jen pro logovani\n",
    "    t = 0 # cislo kroku - jen pro logovani\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.act(obs, r, done)\n",
    "        obs, r, done, _ = env.step(action)\n",
    "        R += r\n",
    "        t += 1\n",
    "        \n",
    "    total_rewards.append(R)    \n",
    "agent.train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní si zobrazíme animaci a graf učení, abychom viděli, jak se náš agent učil. Vidíme, že se moc neučil, což dává smysl, protože nemá implementované žádné rozumné učící se tělo (akce se vybírají náhodně). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.show_animation(agent, env, steps=1000, episodes=5)\n",
    "plt.plot(utils.moving_average(total_rewards, 10))\n",
    "plt.show() \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úkol na cvičení\n",
    "\n",
    "Zkuste si místo náhodného agenta naprogramovat třídu agenta, který se učí chovat v prostředí MountainCar pomocí Q-učení. Dejte pozor na to, že prostředí vrací jako stav spojité hodnoty (poloha i rychlost jsou obě spojité), takže je třeba si z nich nějak udělat prostředí diskrétní (tedy s konečným množstvím stavů). Čím menší budou diskretizované intervaly, tím bude učení přesnější, ale tím déle bude trvat, takže je potřeba najít nějakou rozumnou hranici (ideálně vyzkoušením více hodnot). Dále můžete také experimentovat s dalšími parametry, například měnit maximální počty kroků, případně hodnotu odměny a pozorovat, jak se bude učení měnit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
